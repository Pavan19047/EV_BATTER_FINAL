{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6f8295",
   "metadata": {},
   "source": [
    "# üîã EV Battery Digital Twin - Model Training Notebook\n",
    "\n",
    "This notebook trains two ML models using your **EV Predictive Maintenance Dataset**:\n",
    "1. **RUL Model**: Predicts Remaining Useful Life (cycles remaining)\n",
    "2. **Failure Probability Model**: Predicts probability of battery failure\n",
    "\n",
    "## üìã Instructions\n",
    "1. Run all cells in order (Ctrl+Shift+Enter)\n",
    "2. Models will be saved in the `models/` folder\n",
    "3. Use these models with your live predictor\n",
    "\n",
    "## üìä Dataset Info\n",
    "- **File**: `EV_Predictive_Maintenance_Dataset_15min.csv`\n",
    "- **Records**: 175,393 samples\n",
    "- **Features**: 30 columns (battery, motor, environmental data)\n",
    "- **Targets**: RUL (Remaining Useful Life) and Failure_Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61329d96",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce73e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['numpy', 'pandas', 'scikit-learn', 'xgboost', 'matplotlib', 'seaborn', 'joblib']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package if package != 'scikit-learn' else 'sklearn')\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "print(\"‚úÖ All packages ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488cde2e",
   "metadata": {},
   "source": [
    "## üìö Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2151f",
   "metadata": {},
   "source": [
    "## üìÅ Step 3: Load Dataset\n",
    "\n",
    "Loading the EV Predictive Maintenance Dataset from the datasets folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f542dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to dataset\n",
    "# Try multiple possible paths\n",
    "possible_paths = [\n",
    "    '../datasets/EV_Predictive_Maintenance_Dataset_15min.csv',  # Running from notebooks folder\n",
    "    'datasets/EV_Predictive_Maintenance_Dataset_15min.csv',     # Running from project root\n",
    "    'EV_Predictive_Maintenance_Dataset_15min.csv',             # Running from datasets folder or uploaded\n",
    "]\n",
    "\n",
    "dataset_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        dataset_path = path\n",
    "        break\n",
    "\n",
    "if dataset_path is None:\n",
    "    print(\"‚ùå Dataset not found! Please ensure the file exists in one of these locations:\")\n",
    "    for path in possible_paths:\n",
    "        print(f\"   - {path}\")\n",
    "    print(\"\\nüí° If using Google Colab, upload the file using:\")\n",
    "    print(\"   from google.colab import files\")\n",
    "    print(\"   uploaded = files.upload()\")\n",
    "    raise FileNotFoundError(\"Dataset not found\")\n",
    "    \n",
    "print(f\"üìÇ Loading dataset from: {dataset_path}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"üìä Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nüìã Columns:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad4bad",
   "metadata": {},
   "source": [
    "## üîç Step 4: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"üìä First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display last few rows\n",
    "print(\"\\nüìä Last 5 rows of the dataset:\")\n",
    "display(df.tail())\n",
    "\n",
    "# Data types\n",
    "print(\"\\nüìã Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c580cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"üìà Statistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüîç Missing Values Check:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Missing values detected:\")\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîç Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e421e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variables\n",
    "print(\"üéØ Target Variable Analysis:\")\n",
    "print(\"\\n1. RUL (Remaining Useful Life):\")\n",
    "print(f\"   Min: {df['RUL'].min():.2f} cycles\")\n",
    "print(f\"   Max: {df['RUL'].max():.2f} cycles\")\n",
    "print(f\"   Mean: {df['RUL'].mean():.2f} cycles\")\n",
    "print(f\"   Median: {df['RUL'].median():.2f} cycles\")\n",
    "\n",
    "print(\"\\n2. Failure_Probability:\")\n",
    "print(f\"   Min: {df['Failure_Probability'].min()}\")\n",
    "print(f\"   Max: {df['Failure_Probability'].max()}\")\n",
    "print(f\"   Mean: {df['Failure_Probability'].mean():.4f}\")\n",
    "print(f\"   Unique values: {df['Failure_Probability'].nunique()}\")\n",
    "print(f\"   Value distribution:\\n{df['Failure_Probability'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276411e",
   "metadata": {},
   "source": [
    "## üìä Step 5: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caebd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# RUL distribution\n",
    "axes[0].hist(df['RUL'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('RUL Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Remaining Useful Life (cycles)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axvline(df['RUL'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"RUL\"].mean():.1f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Failure Probability distribution\n",
    "failure_counts = df['Failure_Probability'].value_counts().sort_index()\n",
    "axes[1].bar(failure_counts.index, failure_counts.values, color='salmon', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Failure Probability Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Failure Probability', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3270bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key battery features visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Key Battery Features Distribution', fontsize=16, fontweight='bold')\n",
    "\n",
    "features_to_plot = ['SoC', 'SoH', 'Battery_Voltage', 'Battery_Current', 'Battery_Temperature', 'Charge_Cycles']\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.hist(df[feature], bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(feature, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Value', fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axvline(df[feature].mean(), color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for battery features\n",
    "battery_features = ['SoC', 'SoH', 'Battery_Voltage', 'Battery_Current', \n",
    "                   'Battery_Temperature', 'Charge_Cycles', 'RUL', 'Failure_Probability']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation = df[battery_features].corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Battery Features Correlation Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Strong correlations with RUL:\")\n",
    "rul_corr = correlation['RUL'].sort_values(ascending=False)\n",
    "print(rul_corr[rul_corr.abs() > 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37675e8c",
   "metadata": {},
   "source": [
    "## üîß Step 6: Feature Engineering & Selection\n",
    "\n",
    "We'll select the most relevant features for prediction based on domain knowledge and correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d716914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "# ‚ö†Ô∏è IMPORTANT: Using only COMPLETE features (removed 5 features with ~94% missing values)\n",
    "# Removed: Driving_Speed, Ambient_Temperature, Load_Weight, Distance_Traveled, Component_Health_Score\n",
    "# This will retain 170,000+ samples instead of only 9,899 samples!\n",
    "\n",
    "selected_features = [\n",
    "    'SoC',                    # State of Charge (matches your system) - COMPLETE\n",
    "    'SoH',                    # State of Health (matches your system) - COMPLETE\n",
    "    'Battery_Voltage',        # Battery Voltage (matches your system) - COMPLETE\n",
    "    'Battery_Current',        # Battery Current (matches your system) - COMPLETE\n",
    "    'Battery_Temperature',    # Battery Temperature (matches your system) - COMPLETE\n",
    "    'Charge_Cycles',          # Battery cycles (important for RUL) - COMPLETE\n",
    "    'Power_Consumption',      # Energy usage pattern - COMPLETE\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Selected features for modeling (COMPLETE FEATURES ONLY):\")\n",
    "print(f\"   Using {len(selected_features)} features with no missing values\")\n",
    "print(f\"   Expected to retain >97% of original data (~170,000 samples)\\n\")\n",
    "\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "# Verify all features exist\n",
    "missing_features = [f for f in selected_features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: Missing features: {missing_features}\")\n",
    "    selected_features = [f for f in selected_features if f in df.columns]\n",
    "\n",
    "# Prepare feature matrix\n",
    "X = df[selected_features].copy()\n",
    "\n",
    "# Prepare targets\n",
    "y_rul = df['RUL'].copy()\n",
    "y_failure = df['Failure_Probability'].copy()\n",
    "\n",
    "print(f\"\\nüìä Data prepared:\")\n",
    "print(f\"   Features (X): {X.shape}\")\n",
    "print(f\"   RUL target (y): {y_rul.shape}\")\n",
    "print(f\"   Failure target (y): {y_failure.shape}\")\n",
    "\n",
    "# Check missing values in selected features\n",
    "missing_in_selected = X.isnull().sum()\n",
    "if missing_in_selected.sum() > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing values in selected features:\")\n",
    "    for feat, count in missing_in_selected[missing_in_selected > 0].items():\n",
    "        print(f\"   {feat}: {count:,} ({count/len(X)*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All selected features are complete (no missing values)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: Handle missing and infinite values\n",
    "print(\"\\nüîç Checking for invalid values...\")\n",
    "print(f\"   X NaN count: {X.isnull().sum().sum()}\")\n",
    "print(f\"   X Inf count: {np.isinf(X).sum().sum()}\")\n",
    "print(f\"   y_rul NaN count: {y_rul.isnull().sum()}\")\n",
    "print(f\"   y_rul Inf count: {np.isinf(y_rul).sum()}\")\n",
    "print(f\"   y_failure NaN count: {y_failure.isnull().sum()}\")\n",
    "print(f\"   y_failure Inf count: {np.isinf(y_failure).sum()}\")\n",
    "\n",
    "# Remove rows with NaN or Inf in features or targets\n",
    "initial_size = len(X)\n",
    "valid_indices = ~(X.isnull().any(axis=1) | \n",
    "                  np.isinf(X).any(axis=1) | \n",
    "                  y_rul.isnull() | \n",
    "                  np.isinf(y_rul) |\n",
    "                  y_failure.isnull() |\n",
    "                  np.isinf(y_failure))\n",
    "\n",
    "X = X[valid_indices]\n",
    "y_rul = y_rul[valid_indices]\n",
    "y_failure = y_failure[valid_indices]\n",
    "\n",
    "removed_count = initial_size - len(X)\n",
    "if removed_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Removed {removed_count:,} rows with invalid values ({removed_count/initial_size*100:.2f}%)\")\n",
    "    print(f\"‚úÖ Clean dataset: {len(X):,} samples remaining\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No invalid values found - dataset is clean!\")\n",
    "\n",
    "print(f\"\\nüìä Final data shape:\")\n",
    "print(f\"   Features (X): {X.shape}\")\n",
    "print(f\"   RUL target: {y_rul.shape}\")\n",
    "print(f\"   Failure target: {y_failure.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53799329",
   "metadata": {},
   "source": [
    "## üîç Data Quality Analysis\n",
    "\n",
    "Let's examine why we have so few samples and check for data distribution issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb97e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze why we have so few clean samples\n",
    "print(\"üìä Data Loss Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original dataset size: {len(df):,} samples\")\n",
    "print(f\"After feature selection: {initial_size:,} samples\")\n",
    "print(f\"After cleaning: {len(X):,} samples\")\n",
    "print(f\"Data loss: {initial_size - len(X):,} samples ({(initial_size - len(X))/initial_size*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüîç Analyzing which features caused the most data loss...\")\n",
    "feature_nan_counts = {}\n",
    "for feat in selected_features:\n",
    "    nan_count = df[feat].isnull().sum()\n",
    "    if nan_count > 0:\n",
    "        feature_nan_counts[feat] = nan_count\n",
    "\n",
    "if feature_nan_counts:\n",
    "    print(\"\\nFeatures with missing values:\")\n",
    "    for feat, count in sorted(feature_nan_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   {feat:<25s}: {count:>8,} ({count/len(df)*100:>5.2f}%)\")\n",
    "else:\n",
    "    print(\"   No missing values in selected features\")\n",
    "\n",
    "# Check target distribution\n",
    "print(\"\\nüìä Target Variable Statistics (Clean Data):\")\n",
    "print(f\"RUL range: [{y_rul.min():.2f}, {y_rul.max():.2f}] cycles\")\n",
    "print(f\"RUL mean: {y_rul.mean():.2f} ¬± {y_rul.std():.2f} cycles\")\n",
    "print(f\"Failure distribution: {y_failure.value_counts().to_dict()}\")\n",
    "\n",
    "# Warning if dataset is too small\n",
    "if len(X) < 5000:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Dataset is very small after cleaning!\")\n",
    "    print(f\"   Current size: {len(X):,} samples\")\n",
    "    print(f\"   Recommended: >10,000 samples for robust training\")\n",
    "    print(f\"   This may lead to overfitting or poor generalization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb7ded",
   "metadata": {},
   "source": [
    "## üîÄ Step 7: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_rul_train, y_rul_test = train_test_split(\n",
    "    X, y_rul, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "_, _, y_failure_train, y_failure_test = train_test_split(\n",
    "    X, y_failure, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data split completed!\")\n",
    "print(f\"\\nüìä Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"üìä Test set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Check for invalid values before scaling\n",
    "print(f\"\\nüîç Data Quality Check:\")\n",
    "x_train_nan = X_train.isnull().sum().sum()\n",
    "x_train_inf = np.isinf(X_train.select_dtypes(include=[np.number])).sum().sum()\n",
    "y_rul_train_nan = y_rul_train.isnull().sum()\n",
    "y_rul_train_inf = np.isinf(y_rul_train).sum()\n",
    "y_failure_train_nan = y_failure_train.isnull().sum()\n",
    "y_failure_train_inf = np.isinf(y_failure_train).sum()\n",
    "\n",
    "print(f\"   X_train NaN: {x_train_nan}\")\n",
    "print(f\"   X_train Inf: {x_train_inf}\")\n",
    "print(f\"   y_rul_train NaN: {y_rul_train_nan}\")\n",
    "print(f\"   y_rul_train Inf: {y_rul_train_inf}\")\n",
    "print(f\"   y_failure_train NaN: {y_failure_train_nan}\")\n",
    "print(f\"   y_failure_train Inf: {y_failure_train_inf}\")\n",
    "\n",
    "# Clean data: remove NaN and Inf values\n",
    "total_invalid_train = x_train_nan + x_train_inf + y_rul_train_nan + y_rul_train_inf + y_failure_train_nan + y_failure_train_inf\n",
    "\n",
    "if total_invalid_train > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Cleaning {total_invalid_train} invalid values from training data...\")\n",
    "    \n",
    "    # Create mask for valid rows (convert DataFrame operations to boolean array)\n",
    "    valid_mask_train = ~(X_train.isnull().any(axis=1).values | \n",
    "                         np.isinf(X_train.select_dtypes(include=[np.number])).any(axis=1).values | \n",
    "                         y_rul_train.isnull().values | \n",
    "                         np.isinf(y_rul_train).values |\n",
    "                         y_failure_train.isnull().values |\n",
    "                         np.isinf(y_failure_train).values)\n",
    "    \n",
    "    X_train = X_train[valid_mask_train]\n",
    "    y_rul_train = y_rul_train[valid_mask_train]\n",
    "    y_failure_train = y_failure_train[valid_mask_train]\n",
    "    \n",
    "    print(f\"   Removed {(~valid_mask_train).sum():,} invalid training samples\")\n",
    "    print(f\"   Training set now: {X_train.shape[0]:,} samples\")\n",
    "\n",
    "# Check test set\n",
    "x_test_nan = X_test.isnull().sum().sum()\n",
    "x_test_inf = np.isinf(X_test.select_dtypes(include=[np.number])).sum().sum()\n",
    "y_rul_test_nan = y_rul_test.isnull().sum()\n",
    "y_rul_test_inf = np.isinf(y_rul_test).sum()\n",
    "y_failure_test_nan = y_failure_test.isnull().sum()\n",
    "y_failure_test_inf = np.isinf(y_failure_test).sum()\n",
    "\n",
    "total_invalid_test = x_test_nan + x_test_inf + y_rul_test_nan + y_rul_test_inf + y_failure_test_nan + y_failure_test_inf\n",
    "\n",
    "if total_invalid_test > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Cleaning {total_invalid_test} invalid values from test data...\")\n",
    "    \n",
    "    # Create mask for valid rows (convert DataFrame operations to boolean array)\n",
    "    valid_mask_test = ~(X_test.isnull().any(axis=1).values | \n",
    "                        np.isinf(X_test.select_dtypes(include=[np.number])).any(axis=1).values | \n",
    "                        y_rul_test.isnull().values | \n",
    "                        np.isinf(y_rul_test).values |\n",
    "                        y_failure_test.isnull().values |\n",
    "                        np.isinf(y_failure_test).values)\n",
    "    \n",
    "    X_test = X_test[valid_mask_test]\n",
    "    y_rul_test = y_rul_test[valid_mask_test]\n",
    "    y_failure_test = y_failure_test[valid_mask_test]\n",
    "    \n",
    "    print(f\"   Removed {(~valid_mask_test).sum():,} invalid test samples\")\n",
    "    print(f\"   Test set now: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data cleaning completed!\")\n",
    "print(f\"   Final training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"   Final test set: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Feature scaling completed\")\n",
    "print(f\"   Scaled mean: {X_train_scaled.mean():.6f} (should be ~0)\")\n",
    "print(f\"   Scaled std: {X_train_scaled.std():.6f} (should be ~1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66383506",
   "metadata": {},
   "source": [
    "## ü§ñ Step 8: Train RUL Prediction Model\n",
    "\n",
    "Training XGBoost model to predict Remaining Useful Life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Training RUL Model (XGBoost Regressor)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configure XGBoost for RUL prediction with reduced overfitting\n",
    "rul_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,           # Reduced from 300 to prevent overfitting\n",
    "    max_depth=4,                # Reduced from 8 to prevent overfitting\n",
    "    learning_rate=0.1,          # Increased from 0.05 for better convergence\n",
    "    subsample=0.7,              # More aggressive subsampling\n",
    "    colsample_bytree=0.7,       # More aggressive feature sampling\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    min_child_weight=5,         # Increased from 3 to prevent overfitting\n",
    "    gamma=0.2,                  # Increased regularization\n",
    "    reg_alpha=0.1,              # L1 regularization\n",
    "    reg_lambda=1.0,             # L2 regularization\n",
    "    early_stopping_rounds=10    # Stop if no improvement\n",
    ")\n",
    "\n",
    "print(\"Training with cross-validation and early stopping...\")\n",
    "print(\"This may take a few moments...\\n\")\n",
    "\n",
    "# Train the model with early stopping\n",
    "rul_model.fit(\n",
    "    X_train_scaled, y_rul_train,\n",
    "    eval_set=[(X_train_scaled, y_rul_train), (X_test_scaled, y_rul_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RUL Model training completed!\")\n",
    "print(f\"   Best iteration: {rul_model.best_iteration}\")\n",
    "print(f\"   Total estimators used: {rul_model.n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd10917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RUL model\n",
    "y_rul_pred_train = rul_model.predict(X_train_scaled)\n",
    "y_rul_pred_test = rul_model.predict(X_test_scaled)\n",
    "\n",
    "# Training metrics\n",
    "train_mae = mean_absolute_error(y_rul_train, y_rul_pred_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_rul_train, y_rul_pred_train))\n",
    "train_r2 = r2_score(y_rul_train, y_rul_pred_train)\n",
    "\n",
    "# Test metrics\n",
    "test_mae = mean_absolute_error(y_rul_test, y_rul_pred_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_rul_test, y_rul_pred_test))\n",
    "test_r2 = r2_score(y_rul_test, y_rul_pred_test)\n",
    "\n",
    "print(\"\\nüìä RUL Model Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'Training':<15} {'Test':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'MAE (cycles)':<25} {train_mae:>14.2f} {test_mae:>14.2f}\")\n",
    "print(f\"{'RMSE (cycles)':<25} {train_rmse:>14.2f} {test_rmse:>14.2f}\")\n",
    "print(f\"{'R¬≤ Score':<25} {train_r2:>14.4f} {test_r2:>14.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Detailed diagnosis\n",
    "if test_r2 < 0:\n",
    "    print(\"üö® CRITICAL: Negative R¬≤ Score Detected!\")\n",
    "    print(\"   This means the model performs worse than a simple mean baseline.\")\n",
    "    print(\"   Possible causes:\")\n",
    "    print(\"   1. Severe overfitting (model memorized training noise)\")\n",
    "    print(\"   2. Data distribution mismatch between train/test\")\n",
    "    print(\"   3. Too few samples for reliable training\")\n",
    "    print(\"   4. Features have different distributions in train/test\")\n",
    "    print(\"\\n   Current dataset size: {} samples\".format(len(X)))\n",
    "    print(\"   Train/Test split may have created distribution mismatch\")\n",
    "elif test_r2 > 0.9:\n",
    "    print(\"‚úÖ Excellent model performance! (R¬≤ > 0.9)\")\n",
    "elif test_r2 > 0.8:\n",
    "    print(\"‚úÖ Good model performance! (R¬≤ > 0.8)\")\n",
    "elif test_r2 > 0.7:\n",
    "    print(\"‚úÖ Acceptable performance (R¬≤ > 0.7)\")\n",
    "elif test_r2 > 0.5:\n",
    "    print(\"‚ö†Ô∏è Moderate performance (R¬≤ > 0.5)\")\n",
    "    print(\"   Model has some predictive power but could be improved\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Poor performance (R¬≤ < 0.5)\")\n",
    "    print(\"   Model needs significant improvement\")\n",
    "\n",
    "# Calculate baseline comparison\n",
    "baseline_pred = np.full_like(y_rul_test, y_rul_train.mean())\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_rul_test, baseline_pred))\n",
    "print(f\"\\nüìä Baseline (mean prediction) RMSE: {baseline_rmse:.2f} cycles\")\n",
    "print(f\"   Model RMSE: {test_rmse:.2f} cycles\")\n",
    "if test_rmse < baseline_rmse:\n",
    "    improvement = (baseline_rmse - test_rmse) / baseline_rmse * 100\n",
    "    print(f\"   ‚úÖ Model is {improvement:.1f}% better than baseline\")\n",
    "else:\n",
    "    degradation = (test_rmse - baseline_rmse) / baseline_rmse * 100\n",
    "    print(f\"   ‚ùå Model is {degradation:.1f}% worse than baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RUL predictions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Actual vs Predicted (Test Set)\n",
    "axes[0].scatter(y_rul_test, y_rul_pred_test, alpha=0.4, s=10, color='blue')\n",
    "axes[0].plot([y_rul_test.min(), y_rul_test.max()], \n",
    "             [y_rul_test.min(), y_rul_test.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual RUL (cycles)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted RUL (cycles)', fontsize=12)\n",
    "axes[0].set_title(f'RUL Predictions - Test Set (R¬≤={test_r2:.4f})', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals Plot\n",
    "residuals = y_rul_test - y_rul_pred_test\n",
    "axes[1].scatter(y_rul_pred_test, residuals, alpha=0.4, s=10, color='green')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted RUL (cycles)', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals (cycles)', fontsize=12)\n",
    "axes[1].set_title('Residual Plot', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Error Distribution\n",
    "axes[2].hist(residuals, bins=50, color='orange', edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(x=0, color='r', linestyle='--', lw=2, label='Zero Error')\n",
    "axes[2].set_xlabel('Prediction Error (cycles)', fontsize=12)\n",
    "axes[2].set_ylabel('Frequency', fontsize=12)\n",
    "axes[2].set_title(f'Error Distribution (MAE={test_mae:.2f})', fontsize=13, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f552b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for RUL model\n",
    "importance = rul_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], \n",
    "         color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('RUL Model - Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Top 5 Most Important Features for RUL Prediction:\")\n",
    "for i, row in feature_importance_df.head(5).iterrows():\n",
    "    print(f\"  {row['Feature']:<25s}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963d7d1",
   "metadata": {},
   "source": [
    "## ü§ñ Step 9: Train Failure Probability Model\n",
    "\n",
    "Training XGBoost model to predict Failure Probability (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7eceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Training Failure Prediction Model (XGBoost Regressor)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Note: Failure_Probability appears to be binary (0 or 1)\n",
    "# Configure with regularization to prevent overfitting\n",
    "\n",
    "failure_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,           # Reduced from 300\n",
    "    max_depth=3,                # Reduced from 6\n",
    "    learning_rate=0.1,          # Increased from 0.05\n",
    "    subsample=0.7,              # More aggressive subsampling\n",
    "    colsample_bytree=0.7,       # More aggressive feature sampling\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    min_child_weight=5,         # Increased from 2\n",
    "    gamma=0.2,                  # Increased regularization\n",
    "    reg_alpha=0.1,              # L1 regularization\n",
    "    reg_lambda=1.0,             # L2 regularization\n",
    "    early_stopping_rounds=10    # Stop if no improvement\n",
    ")\n",
    "\n",
    "print(\"Training with cross-validation and early stopping...\")\n",
    "print(\"This may take a few moments...\\n\")\n",
    "\n",
    "# Train the model with early stopping\n",
    "failure_model.fit(\n",
    "    X_train_scaled, y_failure_train,\n",
    "    eval_set=[(X_train_scaled, y_failure_train), (X_test_scaled, y_failure_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Failure Model training completed!\")\n",
    "print(f\"   Best iteration: {failure_model.best_iteration}\")\n",
    "print(f\"   Total estimators used: {failure_model.n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de897aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Failure model\n",
    "y_failure_pred_train = failure_model.predict(X_train_scaled)\n",
    "y_failure_pred_test = failure_model.predict(X_test_scaled)\n",
    "\n",
    "# Clip predictions to [0, 1] range\n",
    "y_failure_pred_train = np.clip(y_failure_pred_train, 0, 1)\n",
    "y_failure_pred_test = np.clip(y_failure_pred_test, 0, 1)\n",
    "\n",
    "# Metrics for regression\n",
    "train_mae_f = mean_absolute_error(y_failure_train, y_failure_pred_train)\n",
    "train_rmse_f = np.sqrt(mean_squared_error(y_failure_train, y_failure_pred_train))\n",
    "train_r2_f = r2_score(y_failure_train, y_failure_pred_train)\n",
    "\n",
    "test_mae_f = mean_absolute_error(y_failure_test, y_failure_pred_test)\n",
    "test_rmse_f = np.sqrt(mean_squared_error(y_failure_test, y_failure_pred_test))\n",
    "test_r2_f = r2_score(y_failure_test, y_failure_pred_test)\n",
    "\n",
    "print(\"\\nüìä Failure Model Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'Training':<15} {'Test':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'MAE':<25} {train_mae_f:>14.4f} {test_mae_f:>14.4f}\")\n",
    "print(f\"{'RMSE':<25} {train_rmse_f:>14.4f} {test_rmse_f:>14.4f}\")\n",
    "print(f\"{'R¬≤ Score':<25} {train_r2_f:>14.4f} {test_r2_f:>14.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# If targets are binary, also show classification metrics\n",
    "if set(y_failure_test.unique()).issubset({0, 1}):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    y_failure_class = (y_failure_pred_test > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_failure_test, y_failure_class)\n",
    "    precision = precision_score(y_failure_test, y_failure_class, zero_division=0)\n",
    "    recall = recall_score(y_failure_test, y_failure_class, zero_division=0)\n",
    "    f1 = f1_score(y_failure_test, y_failure_class, zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüìä Classification Metrics (threshold=0.5):\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "\n",
    "if test_r2_f > 0.8:\n",
    "    print(\"\\n‚úÖ Excellent model performance!\")\n",
    "elif test_r2_f > 0.6:\n",
    "    print(\"\\n‚úÖ Good model performance!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Model performance is acceptable for binary classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Failure predictions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0].scatter(y_failure_test, y_failure_pred_test, alpha=0.4, s=10, color='red')\n",
    "axes[0].plot([0, 1], [0, 1], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Failure Probability', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Failure Probability', fontsize=12)\n",
    "axes[0].set_title(f'Failure Predictions (R¬≤={test_r2_f:.4f})', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim([-0.1, 1.1])\n",
    "axes[0].set_ylim([-0.1, 1.1])\n",
    "\n",
    "# 2. Prediction Distribution\n",
    "axes[1].hist(y_failure_pred_test, bins=50, color='salmon', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0.5, color='red', linestyle='--', lw=2, label='Threshold=0.5')\n",
    "axes[1].set_xlabel('Predicted Failure Probability', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Prediction Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Confusion Matrix (if binary)\n",
    "if set(y_failure_test.unique()).issubset({0, 1}):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    y_failure_class = (y_failure_pred_test > 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_failure_test, y_failure_class)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', ax=axes[2], \n",
    "                xticklabels=['No Failure', 'Failure'],\n",
    "                yticklabels=['No Failure', 'Failure'])\n",
    "    axes[2].set_xlabel('Predicted', fontsize=12)\n",
    "    axes[2].set_ylabel('Actual', fontsize=12)\n",
    "    axes[2].set_title('Confusion Matrix', fontsize=13, fontweight='bold')\n",
    "else:\n",
    "    # Residuals if not binary\n",
    "    residuals_f = y_failure_test - y_failure_pred_test\n",
    "    axes[2].scatter(y_failure_pred_test, residuals_f, alpha=0.4, s=10, color='purple')\n",
    "    axes[2].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[2].set_xlabel('Predicted Failure Probability', fontsize=12)\n",
    "    axes[2].set_ylabel('Residuals', fontsize=12)\n",
    "    axes[2].set_title('Residual Plot', fontsize=13, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa384583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Failure model\n",
    "importance_f = failure_model.feature_importances_\n",
    "feature_importance_df_f = pd.DataFrame({\n",
    "    'Feature': selected_features,\n",
    "    'Importance': importance_f\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_importance_df_f['Feature'], feature_importance_df_f['Importance'], \n",
    "         color='salmon', edgecolor='black')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Failure Model - Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Top 5 Most Important Features for Failure Prediction:\")\n",
    "for i, row in feature_importance_df_f.head(5).iterrows():\n",
    "    print(f\"  {row['Feature']:<25s}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0e686",
   "metadata": {},
   "source": [
    "## üíæ Step 10: Save Models and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "models_dir = '../models'\n",
    "if not os.path.exists(models_dir):\n",
    "    models_dir = 'models'\n",
    "    \n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save RUL model\n",
    "rul_model_path = os.path.join(models_dir, 'rul_xgb_model.joblib')\n",
    "joblib.dump(rul_model, rul_model_path)\n",
    "print(f\"‚úÖ RUL model saved: {rul_model_path}\")\n",
    "\n",
    "# Save Failure model\n",
    "failure_model_path = os.path.join(models_dir, 'failure_xgb_model.joblib')\n",
    "joblib.dump(failure_model, failure_model_path)\n",
    "print(f\"‚úÖ Failure model saved: {failure_model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(models_dir, 'scaler.joblib')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úÖ Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = os.path.join(models_dir, 'feature_names.joblib')\n",
    "joblib.dump(selected_features, feature_names_path)\n",
    "print(f\"‚úÖ Feature names saved: {feature_names_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'n_samples_train': len(X_train),\n",
    "    'n_samples_test': len(X_test),\n",
    "    'n_features': len(selected_features),\n",
    "    'features': selected_features,\n",
    "    'rul_metrics': {\n",
    "        'test_mae': float(test_mae),\n",
    "        'test_rmse': float(test_rmse),\n",
    "        'test_r2': float(test_r2)\n",
    "    },\n",
    "    'failure_metrics': {\n",
    "        'test_mae': float(test_mae_f),\n",
    "        'test_rmse': float(test_rmse_f),\n",
    "        'test_r2': float(test_r2_f)\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(models_dir, 'model_metadata.joblib')\n",
    "joblib.dump(metadata, metadata_path)\n",
    "print(f\"‚úÖ Metadata saved: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ All models and artifacts saved successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8786ca3",
   "metadata": {},
   "source": [
    "## üìä Step 11: Final Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fcdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ Dataset Information:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Dataset: EV_Predictive_Maintenance_Dataset_15min.csv\")\n",
    "print(f\"  Total Records: {len(df):,}\")\n",
    "print(f\"  Training Samples: {len(X_train):,} ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test Samples: {len(X_test):,} ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Features Used: {len(selected_features)}\")\n",
    "\n",
    "print(f\"\\nüîã RUL Prediction Model:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Algorithm: XGBoost Regressor\")\n",
    "print(f\"  Test MAE: {test_mae:.2f} cycles\")\n",
    "print(f\"  Test RMSE: {test_rmse:.2f} cycles\")\n",
    "print(f\"  Test R¬≤: {test_r2:.4f}\")\n",
    "print(f\"  Status: {'‚úÖ Excellent' if test_r2 > 0.9 else '‚úÖ Good' if test_r2 > 0.8 else '‚ö†Ô∏è Acceptable'}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Failure Prediction Model:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  Algorithm: XGBoost Regressor\")\n",
    "print(f\"  Test MAE: {test_mae_f:.4f}\")\n",
    "print(f\"  Test RMSE: {test_rmse_f:.4f}\")\n",
    "print(f\"  Test R¬≤: {test_r2_f:.4f}\")\n",
    "print(f\"  Status: {'‚úÖ Excellent' if test_r2_f > 0.8 else '‚úÖ Good' if test_r2_f > 0.6 else '‚ö†Ô∏è Acceptable'}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Files:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  1. {rul_model_path}\")\n",
    "print(f\"  2. {failure_model_path}\")\n",
    "print(f\"  3. {scaler_path}\")\n",
    "print(f\"  4. {feature_names_path}\")\n",
    "print(f\"  5. {metadata_path}\")\n",
    "\n",
    "print(f\"\\nüîç Top 3 Important Features (RUL):\")\n",
    "for i, row in feature_importance_df.head(3).iterrows():\n",
    "    print(f\"  {row['Feature']:<25s}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîç Top 3 Important Features (Failure):\")\n",
    "for i, row in feature_importance_df_f.head(3).iterrows():\n",
    "    print(f\"  {row['Feature']:<25s}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ TRAINING COMPLETE! Models ready for deployment.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "print(\"  1. Models are saved in the 'models' folder\")\n",
    "print(\"  2. Update your predictor to use these trained models\")\n",
    "print(\"  3. Run: python src/inference/live_predictor.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4cfcc",
   "metadata": {},
   "source": [
    "## üß™ Step 12: Test Prediction Function\n",
    "\n",
    "Test the models with sample data to ensure they work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91139ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample input matching your live system format\n",
    "print(\"üß™ Testing models with sample data...\\n\")\n",
    "\n",
    "# Sample input (using median values from dataset)\n",
    "sample_input = pd.DataFrame({\n",
    "    'SoC': [0.85],\n",
    "    'SoH': [0.94],\n",
    "    'Battery_Voltage': [df['Battery_Voltage'].median()],\n",
    "    'Battery_Current': [df['Battery_Current'].median()],\n",
    "    'Battery_Temperature': [df['Battery_Temperature'].median()],\n",
    "    'Driving_Speed': [60.0],\n",
    "    'Charge_Cycles': [df['Charge_Cycles'].median()],\n",
    "    'Power_Consumption': [df['Power_Consumption'].median()],\n",
    "    'Ambient_Temperature': [25.0],\n",
    "    'Load_Weight': [df['Load_Weight'].median()],\n",
    "    'Distance_Traveled': [df['Distance_Traveled'].median()],\n",
    "    'Component_Health_Score': [0.85]\n",
    "})\n",
    "\n",
    "print(\"üìä Sample Input:\")\n",
    "print(\"-\"*60)\n",
    "for col in sample_input.columns:\n",
    "    print(f\"  {col:<25s}: {sample_input[col].values[0]:>10.3f}\")\n",
    "\n",
    "# Scale the input\n",
    "sample_scaled = scaler.transform(sample_input)\n",
    "\n",
    "# Make predictions\n",
    "rul_prediction = rul_model.predict(sample_scaled)[0]\n",
    "failure_prediction = np.clip(failure_model.predict(sample_scaled)[0], 0, 1)\n",
    "\n",
    "print(\"\\nüîÆ Model Predictions:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"  Remaining Useful Life:    {rul_prediction:>8.2f} cycles\")\n",
    "print(f\"  Failure Probability:      {failure_prediction:>8.4f} ({failure_prediction*100:>6.2f}%)\")\n",
    "\n",
    "# Determine health status\n",
    "if failure_prediction < 0.3:\n",
    "    status = \"‚úÖ HEALTHY\"\n",
    "    color = \"green\"\n",
    "elif failure_prediction < 0.6:\n",
    "    status = \"‚ö†Ô∏è WARNING\"\n",
    "    color = \"orange\"\n",
    "else:\n",
    "    status = \"üö® CRITICAL\"\n",
    "    color = \"red\"\n",
    "\n",
    "print(f\"\\n  Battery Status:           {status}\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Models are working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b7287",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "Your models have been successfully trained and saved. You can now use them with your live predictor.\n",
    "\n",
    "### üì¶ Model Files Location\n",
    "All files are in: `models/` folder\n",
    "\n",
    "### üöÄ Next Steps\n",
    "1. Ensure models are in your project's `models/` folder\n",
    "2. Start your Docker services: `docker compose up -d`\n",
    "3. Start the simulator: `python src/simulator/publisher.py`\n",
    "4. Start the predictor: `python src/inference/live_predictor.py`\n",
    "5. View dashboards at http://localhost:3000\n",
    "\n",
    "### üìö Model Information\n",
    "- **RUL Model**: Predicts remaining battery cycles\n",
    "- **Failure Model**: Predicts failure probability (0-1)\n",
    "- **Features**: 12 carefully selected features\n",
    "- **Algorithm**: XGBoost (tree-based ensemble)\n",
    "- **Format**: Joblib (scikit-learn compatible)\n",
    "\n",
    "**üéä Happy Predicting!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
