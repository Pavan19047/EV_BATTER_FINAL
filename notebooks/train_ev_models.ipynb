{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05814d11",
   "metadata": {},
   "source": [
    "# ğŸ”‹ EV Battery Digital Twin - Model Training Notebook\n",
    "\n",
    "This notebook trains two ML models:\n",
    "1. **RUL Model**: Predicts Remaining Useful Life (battery cycles left)\n",
    "2. **Failure Model**: Predicts probability of battery failure\n",
    "\n",
    "## ğŸ“‹ Instructions\n",
    "1. Upload your dataset (CSV format)\n",
    "2. Run all cells in order\n",
    "3. Download the trained models (.joblib files) at the end\n",
    "\n",
    "## ğŸ“Š Expected Dataset Format\n",
    "Your CSV should have these columns:\n",
    "- `soc` - State of Charge (%)\n",
    "- `soh` - State of Health (%)\n",
    "- `voltage` - Battery Voltage (V)\n",
    "- `current` - Current (A)\n",
    "- `temperature` - Temperature (Â°C)\n",
    "- `speed` - Vehicle Speed (km/h)\n",
    "- `rul` - Target: Remaining Useful Life (cycles)\n",
    "- `failure_prob` - Target: Failure Probability (0-1)\n",
    "\n",
    "**Don't have a dataset?** No problem! This notebook can generate synthetic data for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf00ca",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas scikit-learn xgboost matplotlib seaborn joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b7bcb",
   "metadata": {},
   "source": [
    "## ğŸ“š Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e835d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd8c0a",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 3: Load Your Dataset\n",
    "\n",
    "**Option A**: Upload your own CSV file (recommended)\n",
    "\n",
    "**Option B**: Generate synthetic data (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c95c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Load your CSV file\n",
    "# Uncomment and modify the path to your dataset\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Option B: Generate synthetic data\n",
    "USE_SYNTHETIC_DATA = True  # Set to False if using your own dataset\n",
    "\n",
    "if USE_SYNTHETIC_DATA:\n",
    "    print(\"ğŸ”„ Generating synthetic data...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    \n",
    "    # Generate realistic EV battery data\n",
    "    soc = np.random.uniform(10, 100, n_samples)\n",
    "    soh = np.random.uniform(70, 100, n_samples)\n",
    "    voltage = 300 + (soc / 100) * 100 + np.random.normal(0, 5, n_samples)\n",
    "    current = np.random.uniform(-200, 200, n_samples)\n",
    "    temperature = np.random.uniform(15, 45, n_samples)\n",
    "    speed = np.random.uniform(0, 120, n_samples)\n",
    "    \n",
    "    # Generate target variables\n",
    "    # RUL depends on SOH, temperature, and usage patterns\n",
    "    rul = (soh / 100) * 1000 - (temperature - 25) * 10 + np.random.normal(0, 50, n_samples)\n",
    "    rul = np.clip(rul, 0, 1000)\n",
    "    \n",
    "    # Failure probability inversely related to SOH and RUL\n",
    "    failure_prob = 1 - (soh / 100) * (rul / 1000) + np.random.normal(0, 0.1, n_samples)\n",
    "    failure_prob = np.clip(failure_prob, 0, 1)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'soc': soc,\n",
    "        'soh': soh,\n",
    "        'voltage': voltage,\n",
    "        'current': current,\n",
    "        'temperature': temperature,\n",
    "        'speed': speed,\n",
    "        'rul': rul,\n",
    "        'failure_prob': failure_prob\n",
    "    })\n",
    "    print(f\"âœ… Generated {len(df):,} synthetic samples\")\n",
    "else:\n",
    "    # If you're using Colab, uncomment this to upload your file\n",
    "    # from google.colab import files\n",
    "    # uploaded = files.upload()\n",
    "    # df = pd.read_csv(list(uploaded.keys())[0])\n",
    "    pass\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"\\nğŸ“‹ Dataset info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f43e10",
   "metadata": {},
   "source": [
    "## ğŸ” Step 4: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e48f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"ğŸ“Š First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nğŸ“ˆ Statistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nğŸ” Missing values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"âœ… No missing values found!\")\n",
    "else:\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    ax = axes[idx // 4, idx % 4]\n",
    "    ax.hist(df[col], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(col.upper(), fontweight='bold')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b622cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation = df.corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ef0e6",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 5: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "feature_columns = ['soc', 'soh', 'voltage', 'current', 'temperature', 'speed']\n",
    "X = df[feature_columns].values\n",
    "\n",
    "# Two target variables\n",
    "y_rul = df['rul'].values\n",
    "y_failure = df['failure_prob'].values\n",
    "\n",
    "print(f\"âœ… Features shape: {X.shape}\")\n",
    "print(f\"âœ… RUL target shape: {y_rul.shape}\")\n",
    "print(f\"âœ… Failure target shape: {y_failure.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_rul_train, y_rul_test = train_test_split(\n",
    "    X, y_rul, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "_, _, y_failure_train, y_failure_test = train_test_split(\n",
    "    X, y_failure, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"âœ… Training set size: {X_train.shape[0]:,} samples\")\n",
    "print(f\"âœ… Test set size: {X_test.shape[0]:,} samples\")\n",
    "print(f\"âœ… Split ratio: {X_train.shape[0]/X.shape[0]*100:.1f}% train / {X_test.shape[0]/X.shape[0]*100:.1f}% test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… Feature scaling completed\")\n",
    "print(f\"\\nScaled feature means (should be ~0): {X_train_scaled.mean(axis=0).round(4)}\")\n",
    "print(f\"Scaled feature stds (should be ~1): {X_train_scaled.std(axis=0).round(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae888aa7",
   "metadata": {},
   "source": [
    "## ğŸ¤– Step 6: Train RUL Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Training RUL Model (XGBoost)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configure XGBoost for RUL prediction\n",
    "rul_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rul_model.fit(\n",
    "    X_train_scaled, y_rul_train,\n",
    "    eval_set=[(X_test_scaled, y_rul_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"âœ… RUL Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RUL model\n",
    "y_rul_pred = rul_model.predict(X_test_scaled)\n",
    "\n",
    "rul_mae = mean_absolute_error(y_rul_test, y_rul_pred)\n",
    "rul_rmse = np.sqrt(mean_squared_error(y_rul_test, y_rul_pred))\n",
    "rul_r2 = r2_score(y_rul_test, y_rul_pred)\n",
    "\n",
    "print(\"\\nğŸ“Š RUL Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean Absolute Error (MAE):  {rul_mae:.2f} cycles\")\n",
    "print(f\"Root Mean Squared Error:     {rul_rmse:.2f} cycles\")\n",
    "print(f\"RÂ² Score:                    {rul_r2:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if rul_r2 > 0.9:\n",
    "    print(\"âœ… Excellent model performance! (RÂ² > 0.9)\")\n",
    "elif rul_r2 > 0.8:\n",
    "    print(\"âœ… Good model performance! (RÂ² > 0.8)\")\n",
    "else:\n",
    "    print(\"âš ï¸ Model performance could be improved (RÂ² < 0.8)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RUL predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_rul_test, y_rul_pred, alpha=0.5, s=20)\n",
    "axes[0].plot([y_rul_test.min(), y_rul_test.max()], \n",
    "             [y_rul_test.min(), y_rul_test.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual RUL (cycles)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted RUL (cycles)', fontsize=12)\n",
    "axes[0].set_title(f'RUL Predictions (RÂ²={rul_r2:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_rul_test - y_rul_pred\n",
    "axes[1].scatter(y_rul_pred, residuals, alpha=0.5, s=20)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted RUL (cycles)', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals (cycles)', fontsize=12)\n",
    "axes[1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for RUL model\n",
    "plt.figure(figsize=(10, 6))\n",
    "importance = rul_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.bar(range(len(importance)), importance[indices], color='skyblue', edgecolor='black')\n",
    "plt.xticks(range(len(importance)), [feature_columns[i] for i in indices], rotation=45)\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Importance', fontsize=12)\n",
    "plt.title('RUL Model - Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ” Top 3 Most Important Features for RUL:\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. {feature_columns[indices[i]]}: {importance[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbc8f6",
   "metadata": {},
   "source": [
    "## ğŸ¤– Step 7: Train Failure Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4309ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Training Failure Prediction Model (XGBoost)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configure XGBoost for failure probability prediction\n",
    "failure_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "failure_model.fit(\n",
    "    X_train_scaled, y_failure_train,\n",
    "    eval_set=[(X_test_scaled, y_failure_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"âœ… Failure Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f642fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Failure model\n",
    "y_failure_pred = failure_model.predict(X_test_scaled)\n",
    "y_failure_pred = np.clip(y_failure_pred, 0, 1)  # Ensure predictions are in [0, 1]\n",
    "\n",
    "failure_mae = mean_absolute_error(y_failure_test, y_failure_pred)\n",
    "failure_rmse = np.sqrt(mean_squared_error(y_failure_test, y_failure_pred))\n",
    "failure_r2 = r2_score(y_failure_test, y_failure_pred)\n",
    "\n",
    "print(\"\\nğŸ“Š Failure Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean Absolute Error (MAE):  {failure_mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error:     {failure_rmse:.4f}\")\n",
    "print(f\"RÂ² Score:                    {failure_r2:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if failure_r2 > 0.7:\n",
    "    print(\"âœ… Good model performance! (RÂ² > 0.7)\")\n",
    "elif failure_r2 > 0.5:\n",
    "    print(\"âœ… Acceptable model performance (RÂ² > 0.5)\")\n",
    "else:\n",
    "    print(\"âš ï¸ Model performance could be improved (RÂ² < 0.5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Failure predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[0].scatter(y_failure_test, y_failure_pred, alpha=0.5, s=20)\n",
    "axes[0].plot([0, 1], [0, 1], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Failure Probability', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Failure Probability', fontsize=12)\n",
    "axes[0].set_title(f'Failure Predictions (RÂ²={failure_r2:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim([0, 1])\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Residuals\n",
    "residuals = y_failure_test - y_failure_pred\n",
    "axes[1].scatter(y_failure_pred, residuals, alpha=0.5, s=20)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Failure Probability', fontsize=12)\n",
    "axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "axes[1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e00bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Failure model\n",
    "plt.figure(figsize=(10, 6))\n",
    "importance = failure_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.bar(range(len(importance)), importance[indices], color='salmon', edgecolor='black')\n",
    "plt.xticks(range(len(importance)), [feature_columns[i] for i in indices], rotation=45)\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Importance', fontsize=12)\n",
    "plt.title('Failure Model - Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ” Top 3 Most Important Features for Failure:\")\n",
    "for i in range(3):\n",
    "    print(f\"  {i+1}. {feature_columns[indices[i]]}: {importance[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b240b",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 8: Save Models and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save RUL model\n",
    "rul_model_path = 'models/rul_xgb_model.joblib'\n",
    "joblib.dump(rul_model, rul_model_path)\n",
    "print(f\"âœ… RUL model saved to: {rul_model_path}\")\n",
    "\n",
    "# Save Failure model\n",
    "failure_model_path = 'models/failure_xgb_model.joblib'\n",
    "joblib.dump(failure_model, failure_model_path)\n",
    "print(f\"âœ… Failure model saved to: {failure_model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = 'models/scaler.joblib'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"âœ… Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = 'models/feature_names.joblib'\n",
    "joblib.dump(feature_columns, feature_names_path)\n",
    "print(f\"âœ… Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ‰ All models saved successfully!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a791059",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 9: Model Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93352e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š FINAL MODEL SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nğŸ”‹ RUL Prediction Model (XGBoost)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Model Type:           XGBoost Regressor\")\n",
    "print(f\"  Number of Features:   {len(feature_columns)}\")\n",
    "print(f\"  Training Samples:     {X_train.shape[0]:,}\")\n",
    "print(f\"  Test Samples:         {X_test.shape[0]:,}\")\n",
    "print(f\"  MAE:                  {rul_mae:.2f} cycles\")\n",
    "print(f\"  RMSE:                 {rul_rmse:.2f} cycles\")\n",
    "print(f\"  RÂ² Score:             {rul_r2:.4f}\")\n",
    "\n",
    "print(\"\\nâš ï¸ Failure Prediction Model (XGBoost)\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Model Type:           XGBoost Regressor\")\n",
    "print(f\"  Number of Features:   {len(feature_columns)}\")\n",
    "print(f\"  Training Samples:     {X_train.shape[0]:,}\")\n",
    "print(f\"  Test Samples:         {X_test.shape[0]:,}\")\n",
    "print(f\"  MAE:                  {failure_mae:.4f}\")\n",
    "print(f\"  RMSE:                 {failure_rmse:.4f}\")\n",
    "print(f\"  RÂ² Score:             {failure_r2:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“ Saved Files:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  1. {rul_model_path}\")\n",
    "print(f\"  2. {failure_model_path}\")\n",
    "print(f\"  3. {scaler_path}\")\n",
    "print(f\"  4. {feature_names_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Training Complete! Download the models folder.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfaec5",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 10: Test Predictions on Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample input\n",
    "print(\"ğŸ§ª Testing models with sample data...\\n\")\n",
    "\n",
    "# Create sample input\n",
    "sample_data = np.array([[\n",
    "    85.0,   # soc\n",
    "    95.0,   # soh\n",
    "    380.0,  # voltage\n",
    "    -50.0,  # current\n",
    "    25.0,   # temperature\n",
    "    60.0    # speed\n",
    "]])\n",
    "\n",
    "# Scale the input\n",
    "sample_scaled = scaler.transform(sample_data)\n",
    "\n",
    "# Make predictions\n",
    "rul_pred = rul_model.predict(sample_scaled)[0]\n",
    "failure_pred = np.clip(failure_model.predict(sample_scaled)[0], 0, 1)\n",
    "\n",
    "print(\"ğŸ“Š Input Data:\")\n",
    "print(\"-\" * 60)\n",
    "for i, col in enumerate(feature_columns):\n",
    "    print(f\"  {col:15s}: {sample_data[0][i]:8.2f}\")\n",
    "\n",
    "print(\"\\nğŸ”® Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  RUL:              {rul_pred:.2f} cycles\")\n",
    "print(f\"  Failure Prob:     {failure_pred:.4f} ({failure_pred*100:.2f}%)\")\n",
    "\n",
    "# Health status\n",
    "if failure_pred < 0.3:\n",
    "    status = \"âœ… HEALTHY\"\n",
    "elif failure_pred < 0.6:\n",
    "    status = \"âš ï¸ WARNING\"\n",
    "else:\n",
    "    status = \"ğŸš¨ CRITICAL\"\n",
    "    \n",
    "print(f\"\\n  Battery Status:   {status}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68cfde",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 11: Download Models (For Google Colab)\n",
    "\n",
    "Uncomment the code below if you're using Google Colab to download the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell if running on Google Colab\n",
    "# from google.colab import files\n",
    "# import shutil\n",
    "\n",
    "# # Create a zip file of the models folder\n",
    "# shutil.make_archive('ev_models', 'zip', 'models')\n",
    "\n",
    "# # Download the zip file\n",
    "# files.download('ev_models.zip')\n",
    "\n",
    "# print(\"âœ… Models downloaded as 'ev_models.zip'\")\n",
    "# print(\"Extract the zip file and place the .joblib files in your project's 'models' folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f80eb",
   "metadata": {},
   "source": [
    "## ğŸ“ Next Steps\n",
    "\n",
    "1. **Download** all `.joblib` files from the `models` folder\n",
    "2. **Copy** them to your project: `C:\\Users\\pavan\\OneDrive\\Desktop\\EV_BATTER_FINAL\\models\\`\n",
    "3. **Run** your predictor:\n",
    "   ```powershell\n",
    "   python src\\inference\\live_predictor.py --interval 5 --write-back\n",
    "   ```\n",
    "\n",
    "## ğŸ¯ Files You Need\n",
    "- `rul_xgb_model.joblib` - RUL prediction model\n",
    "- `failure_xgb_model.joblib` - Failure prediction model\n",
    "- `scaler.joblib` - Feature scaler\n",
    "- `feature_names.joblib` - Feature column names\n",
    "\n",
    "## ğŸ“š Model Details\n",
    "- **Algorithm**: XGBoost (Extreme Gradient Boosting)\n",
    "- **Input Features**: SOC, SOH, Voltage, Current, Temperature, Speed\n",
    "- **Output 1**: Remaining Useful Life (cycles)\n",
    "- **Output 2**: Failure Probability (0-1)\n",
    "- **Framework**: scikit-learn compatible (joblib serialization)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ Training Complete! Your models are ready for deployment.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
